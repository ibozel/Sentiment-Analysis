# -*- coding: utf-8 -*-
"""Sentiment_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OzlrslpsXzbNdx-VVxdrf5IQDyfpOuPb
"""

import numpy as np
import pandas as pd

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense ,GRU, Embedding
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences

dataset=pd.read_csv('hepsiburada.csv')

dataset.head(20)

dataset.shape

target=dataset['Rating'].values.tolist()

data=dataset['Review'].values.tolist()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test=train_test_split(data,target,test_size=0.20, random_state=42)

x_train[410]

x_train[1000]

num_words=10000
tokenizer=Tokenizer(num_words=num_words)

tokenizer.fit_on_texts(data)

tokenizer.word_index

x_train_tokens=tokenizer.texts_to_sequences(x_train)

x_train[800]

print(x_train_tokens[800])

x_test_tokens=tokenizer.texts_to_sequences(x_test)

num_tokens=[len(tokens) for tokens in x_train_tokens + x_test_tokens]

num_tokens=np.array(num_tokens)

num_tokens

np.mean(num_tokens)

np.max(num_tokens)

np.argmax(num_tokens)

max_tokens=np.mean(num_tokens)+2*np.std(num_tokens)

max_tokens

max_tokens=int(max_tokens)

max_tokens

np.sum(num_tokens<max_tokens)/len(num_tokens)

"""Padding
---
"""

x_train_pad=pad_sequences(x_train_tokens, maxlen=max_tokens)

x_test_pad=pad_sequences(x_test_tokens, maxlen=max_tokens)

np.array(x_train_tokens[800])

x_train_pad[800]

"""Keras içine token verip string olarak almak  için fonksiyon yazalım"""

idx=tokenizer.word_index

inverse_map=dict(zip(idx.values(), idx.keys()))

def tokens_string(tokens):
  words=[inverse_map[token] for token in tokens if token!=0]
  text=' '.join(words)
  return text

x_train[800]

tokens_string(x_train_tokens[800])

"""MODEL OLUŞTUMA
---
"""

model = Sequential()

embedding_size=50

model.add(Embedding(input_dim=num_words,
                    output_dim=embedding_size,
                    input_length=max_tokens,
                    name='embedding_layer'))

model.add(GRU(units=16, return_sequences=True))
model.add(GRU(units=8, return_sequences=True))
model.add(GRU(units=4, ))
model.add(Dense(1, activation='sigmoid'))

optimizer=Adam(lr=1e-3)

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model.summary()

y_train=np.array(y_train)

model.fit(x_train_pad, y_train, epochs=4 ,batch_size=256)

y_test=np.array(y_test)

result=model.evaluate(x_test_pad, y_test)

result[0]

y_pred=model.predict(x=x_test_pad[0:1000])

y_pred=y_pred.T[0]

    cls_pred=np.array([1.0 if p>0.5 else 0.0 for p in y_pred])

cls_true=np.array(y_test[0:1000])

incorrect=np.where(cls_pred!=cls_true)

incorrect=incorrect[0]

len(incorrect)

idx=incorrect[1]

idx

text=x_test[idx]

text

y_pred[idx]

    cls_true[idx]

"""Kendimiz Text oluşturalım"""

text1="bu ürün çok iyi herkese tavsiye ederim"
text2="kargo berbat paketleme rezil, şikayet edecem"
text3="ben bu ürünü herkese tavsiye etmedim değil"
text4="eh işte"
text5="ürün zort çıktı"
text6="ürün çok iyi ancak paketleme kötü"
text7="ürün sahte çıktı"
text8="yorumlar abartılı"
text9="tam bir fiyat performans ürünü"
text10="kötü yorumlar gözümü korkutmuştu ancak sorun yaşamadım"
texts=[text1,text2,text3,text4,text5, text6 ,text7,text8,text9 ,text10]

tokens=tokenizer.texts_to_sequences(texts)

tokens_pad=pad_sequences(tokens,maxlen=max_tokens)

tokens_pad.shape

model.predict(tokens_pad)

"""OBJECT-ORIENTED
---
"""

liste=[1,2,3,4,5,6]

liste.append(7)

print(liste)

type(liste)

"""Sınıf"""

class Araba():
  model="Renault Kadjar"
  renk="metalik gri"
  beygir_gücü=150
  silindir=4

araba1=Araba() # Araba1 objesinin veri tipi araba

type(araba1)

araba1.model

araba1.renk

araba2=Araba()

araba2.silindir

dir(araba1)

